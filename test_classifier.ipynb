{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Lq52rMMuejyr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('jet')\n",
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn, sklearn.model_selection\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Xc4r6rP7ejyv",
    "outputId": "bf5ba06b-09e0-4f73-aa1f-722b1b182f9f"
   },
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.cuda.manual_seed_all(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "W1LMw4aIejy0"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "arFkyRlTejz_"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=8,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.out = nn.Linear(440, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output, x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "skI4RsFQej0V",
    "outputId": "4d6f0977-a754-4e8c-8abd-5365b09e2c0a"
   },
   "outputs": [],
   "source": [
    "cnn = CNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DSAbFbyVej0v"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./classifier_model.pth')\n",
    "cnn.load_state_dict(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "ydDLQk0jej0z",
    "outputId": "c2a825b0-7416-4b4a-cfd6-adcb79372845",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CjjJAIV3ej1H"
   },
   "outputs": [],
   "source": [
    "class SubsetSampler(torch.utils.data.sampler.Sampler):\n",
    "    def __init__(self, indices):\n",
    "        self.indices = indices\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mytransform = torchvision.transforms.Compose([\n",
    "   torchvision.transforms.Resize(100),\n",
    "   torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if model == 'cycle_gan':\n",
    "    thispath = './cyclegan/results/brats2013_cyclegan_'\n",
    "else:\n",
    "    thispath = './cyclegan/results/brats2013_pix2pix_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "kTppdx3_ej1V",
    "outputId": "83167952-e4c6-474a-dc3a-b81afd66d0e3"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for percent in [\n",
    "        '0.0', '0.1', '0.2', '0.3', '0.4', '0.5',\n",
    "        '0.6', '0.7', '0.8', '0.9', '1.0']:\n",
    "\n",
    "    path = thispath + percent + '/test_latest/'\n",
    "    test_data_raw = torchvision.datasets.ImageFolder(\n",
    "        path, transform=mytransform)\n",
    "\n",
    "    labels = np.asarray(\n",
    "        ['True' in img for img in np.asarray(test_data_raw.imgs)[:, 0]])\n",
    "    fake_b_samples = np.where(\n",
    "        ['fake_B' in img for img in np.asarray(test_data_raw.imgs)[:, 0]])[0]\n",
    "    real_b_samples = np.where(\n",
    "        ['real_B' in img for img in np.asarray(test_data_raw.imgs)[:, 0]])[0]\n",
    "\n",
    "    test_fake_b_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_data_raw, batch_size=len(test_data_raw), shuffle=False,\n",
    "        sampler=SubsetSampler(fake_b_samples))\n",
    "    test_real_b_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_data_raw, batch_size=len(test_data_raw),\n",
    "        shuffle=False, sampler=SubsetSampler(real_b_samples))\n",
    "\n",
    "    test_fake_b_data = list(test_fake_b_loader)\n",
    "    test_real_b_data = list(test_real_b_loader)\n",
    "    test_fake_b_x = Variable(test_fake_b_data[0][0])\n",
    "    test_fake_b_y = test_fake_b_data[0][1]\n",
    "\n",
    "    cnn.eval()\n",
    "    r = cnn(test_fake_b_x)\n",
    "\n",
    "    pred_y = torch.max(r[0], 1)[1].data.squeeze().numpy()\n",
    "\n",
    "    acc = (pred_y == labels[fake_b_samples]).mean()\n",
    "\n",
    "    dist_0 = pred_y[labels[fake_b_samples] == 0].mean()\n",
    "    dist_1 = pred_y[labels[fake_b_samples] == 1].mean()\n",
    "\n",
    "    diff = np.abs(\n",
    "        (test_fake_b_data[0][0].numpy() - test_real_b_data[0][0].numpy()))\n",
    "    diff_per_image = diff.mean(axis=(1, 2, 3))\n",
    "\n",
    "    diff_0 = diff_per_image[labels[fake_b_samples] == 0].mean()\n",
    "    diff_1 = diff_per_image[labels[fake_b_samples] == 1].mean()\n",
    "\n",
    "    results.append([\n",
    "        percent, pred_y.mean(), acc, dist_0, dist_1,\n",
    "        collections.Counter(pred_y), diff_0, diff_1])  \n",
    "\n",
    "    print(\n",
    "        'Percent:', percent,\n",
    "        ' Tumors:', pred_y.mean(),\n",
    "        ' ', collections.Counter(pred_y),\n",
    "        ' ', diff_0, diff_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perc = np.asarray(results)[:, 3].astype(np.float)\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.bar(\n",
    "    range(perc.shape[0]), 1 - perc, bottom=perc,\n",
    "    color='forestgreen', label='Predicted without Tumor')\n",
    "ax1.bar(\n",
    "    range(perc.shape[0]), perc,\n",
    "    color='tomato', label='Predicted with Tumor')\n",
    "ax1.set_ylabel('Percentage of transformed samples')\n",
    "ax1.set_xlabel('Percentage of tumor images in the target domain during training')\n",
    "ax1.set_title('Transformed healthy images from the holdout set')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "t = np.arange(11)\n",
    "s2 = np.asarray(results)[:, 6].astype(np.float)\n",
    "ax2.set_ylim(ymax=0.03, ymin=0.005)\n",
    "ax2.plot(t, s2, 'black', label='Pixel Error (MAE)')\n",
    "\n",
    "ax2.set_ylabel('Pixel Error (MAE)')\n",
    "ax2.legend(loc='lower right')\n",
    "fig.tight_layout()\n",
    "plt.xticks(range(11), [\n",
    "    '0%', '10%', '20%', '30%', '40%', '50%',\n",
    "    '60%', '70%', '80%', '90%', '100%'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "23wsQBEPej1t"
   },
   "outputs": [],
   "source": [
    "perc = np.asarray(results)[:, 4].astype(np.float)\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.bar(\n",
    "    range(perc.shape[0]), 1 - perc, bottom=perc,\n",
    "    color='forestgreen', label='Predicted without Tumor')\n",
    "ax1.bar(\n",
    "    range(perc.shape[0]), perc,\n",
    "    color='tomato', label='Predicted with Tumor')\n",
    "ax1.set_ylabel('Percentage of transformed samples')\n",
    "ax1.set_xlabel('Percentage of tumor images in the target domain during training')\n",
    "ax1.set_title('Transformed tumor images from the holdout set')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "t = np.arange(11)\n",
    "s2 = np.asarray(results)[:, 7].astype(np.float)\n",
    "ax2.set_ylim(ymax=0.03, ymin=0.005)\n",
    "ax2.plot(t, s2, 'black', label='Pixel Error (MAE)')\n",
    "\n",
    "ax2.set_ylabel('Pixel Error (MAE)')\n",
    "ax2.legend(loc='lower right')\n",
    "fig.tight_layout()\n",
    "plt.xticks(range(11), [\n",
    "    '0%', '10%', '20%', '30%', '40%', '50%',\n",
    "    '60%', '70%', '80%', '90%', '100%'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classify.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
